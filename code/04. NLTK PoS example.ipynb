{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Natural language toolkit is an entry point for all contemporary NLP tools\n",
    "# pip install nltk \n",
    "#  - if not a part of your python environment\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: before calling this method elsewhere - \n",
    "# better download the data from http://www.nltk.org/data.html\n",
    "# whole package is ~3G\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['This', 'is', 'a', 'sentence', 'that', 'we', 'will', 'use', 'to', 'test', 'the', 'magic', 'tool']\n",
      "Tagged: [('This', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('sentence', 'NOUN'), ('that', 'ADP'), ('we', 'PRON'), ('will', 'VERB'), ('use', 'VERB'), ('to', 'PRT'), ('test', 'VERB'), ('the', 'DET'), ('magic', 'NOUN'), ('tool', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "# text tokenization and tagging\n",
    "text = \"This is a sentence that we will use to test the magic tool\"\n",
    "\n",
    "# requires tokenizers/punkt/english.pickle of nltk_data\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# tag meanings are here http://www.nltk.org/book/ch05.html\n",
    "tagged = nltk.pos_tag(tokens, tagset='universal')\n",
    "print(\"Tagged:\", tagged)\n",
    "\n",
    "# NB: see PoS for \"magic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram: [('This', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('sentence', 'NOUN'), ('that', 'ADP'), ('we', 'PRON'), ('will', 'VERB'), ('use', 'NOUN'), ('to', 'PRT'), ('test', 'NOUN'), ('the', 'DET'), ('magic', 'ADJ'), ('tool', 'NOUN')]\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "BROWN CORPUS\n",
      "\n",
      "A Standard Corpus of Present-Day Edited American\n",
      "English, for use with Digital Computers.\n",
      "\n",
      "by W. N. Francis and H. Kucera (1964)\n",
      "Department of Linguistics, Brown University\n",
      "Providence, Rhode Island, USA\n",
      "\n",
      "Revised 1971, Revised and Amplified 1979\n",
      "\n",
      "http://www.hit.uib.no/icame/brown/bcm.html\n",
      "\n",
      "Distributed with the permission of the copyright holder,\n",
      "redistribution permitted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use this corpus to indentify parts of speech\n",
    "from nltk.corpus import brown    # 500 documents, ~1M words, biggest in NLTK\n",
    "\n",
    "# universal, because default tagset in different from conventional\n",
    "# https://en.wikipedia.org/wiki/Brown_Corpus\n",
    "brown_tagged_sents = brown.tagged_sents(tagset='universal')\n",
    "# brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "\n",
    "# unigram tagger does not consider any context, \n",
    "# that's why it can make mistakes for words like \"TEST\"\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "tagged_u = unigram_tagger.tag(tokens)\n",
    "print(\"unigram:\", tagged_u)\n",
    "\n",
    "# what does they mean?\n",
    "nltk.help.upenn_tagset('JJ')\n",
    "\n",
    "# cropora provide readme!\n",
    "print(nltk.corpus.brown.readme())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram: [('This', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('sentence', 'NOUN'), ('that', 'PRON'), ('we', 'PRON'), ('will', 'VERB'), ('use', 'VERB'), ('to', 'PRT'), ('test', 'VERB'), ('the', 'DET'), ('magic', 'ADJ'), ('tool', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(brown_tagged_sents)\n",
    "tagged_b = bigram_tagger.tag(tokens)\n",
    "print(\"bigram:\", tagged_b)\n",
    "\n",
    "# see word test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
