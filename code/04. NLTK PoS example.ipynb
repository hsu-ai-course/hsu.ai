{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: before calling this method elsewhere - \n",
    "# better download the data from http://www.nltk.org/data.html\n",
    "# whole package is ~3G\n",
    "# nltk.download()\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['This', 'is', 'a', 'sentence', 'that', 'we', 'will', 'use', 'to', 'test', 'the', 'magic', 'tool']\n",
      "Tagged: [('This', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('sentence', 'NOUN'), ('that', 'ADP'), ('we', 'PRON'), ('will', 'VERB'), ('use', 'VERB'), ('to', 'PRT'), ('test', 'VERB'), ('the', 'DET'), ('magic', 'NOUN'), ('tool', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "# text tokenization and tagging\n",
    "text = \"This is a sentence that we will use to test the magic tool\"\n",
    "\n",
    "# requires tokenizers/punkt/english.pickle of nltk_data\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# tag meanings are here http://www.nltk.org/book/ch05.html\n",
    "tagged = nltk.pos_tag(tokens, tagset='universal')\n",
    "print(\"Tagged:\", tagged)\n",
    "\n",
    "# NB: see PoS for \"magic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram: [('This', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('sentence', 'NOUN'), ('that', 'ADP'), ('we', 'PRON'), ('will', 'VERB'), ('use', 'NOUN'), ('to', 'PRT'), ('test', 'NOUN'), ('the', 'DET'), ('magic', 'ADJ'), ('tool', 'NOUN')]\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "BROWN CORPUS\n",
      "\n",
      "A Standard Corpus of Present-Day Edited American\n",
      "English, for use with Digital Computers.\n",
      "\n",
      "by W. N. Francis and H. Kucera (1964)\n",
      "Department of Linguistics, Brown University\n",
      "Providence, Rhode Island, USA\n",
      "\n",
      "Revised 1971, Revised and Amplified 1979\n",
      "\n",
      "http://www.hit.uib.no/icame/brown/bcm.html\n",
      "\n",
      "Distributed with the permission of the copyright holder,\n",
      "redistribution permitted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use this corpus to indentify parts of speech\n",
    "from nltk.corpus import brown    # 500 documents, ~1M words, biggest in NLTK\n",
    "\n",
    "# universal, because default tagset in different from conventional\n",
    "# https://en.wikipedia.org/wiki/Brown_Corpus\n",
    "brown_tagged_sents = brown.tagged_sents(tagset='universal')\n",
    "# brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "\n",
    "# unigram tagger does not consider any context, \n",
    "# that's why it can make mistakes for words like \"TEST\"\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "tagged_u = unigram_tagger.tag(tokens)\n",
    "print(\"unigram:\", tagged_u)\n",
    "\n",
    "# what does they mean?\n",
    "nltk.help.upenn_tagset('JJ')\n",
    "\n",
    "# cropora provide readme!\n",
    "print(nltk.corpus.brown.readme())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram: [('This', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('sentence', 'NOUN'), ('that', 'PRON'), ('we', 'PRON'), ('will', 'VERB'), ('use', 'VERB'), ('to', 'PRT'), ('test', 'VERB'), ('the', 'DET'), ('magic', 'ADJ'), ('tool', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(brown_tagged_sents)\n",
    "tagged_b = bigram_tagger.tag(tokens)\n",
    "print(\"bigram:\", tagged_b)\n",
    "\n",
    "# see word test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
